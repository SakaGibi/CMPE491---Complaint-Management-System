# -*- coding: utf-8 -*-
"""492_model_v3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cuheANF-XBUIyi7li0JsQgJr_sEEJaGF
"""

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, precision_recall_fscore_support
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer

from google.colab import drive
drive.mount('/content/drive')
import os
os.chdir("drive/MyDrive/Colab Notebooks")

df_original = pd.read_csv("sikayet_v1.csv")
df = df_original.copy()

file_name = 'sikayet_v1.csv'
try:
    print(f"'{file_name}' veri seti başarıyla yüklendi.")
    print(f"Veri seti boyutu: {df.shape[0]} satır, {df.shape[1]} sütun")

    print("\n--- İlk 5 Satır ---")
    print(df.head())

    print("\n--- Veri Seti Bilgisi ---")
    df.info()

    print("\n--- Eksik Veri Kontrolü ---")
    print(df.isnull().sum())
    if df.isnull().sum().any():
        print("\nUyarı: Veri setinde eksik değerler var. Stratejinizi belirleyin (doldurma/silme).")
    else:
        print("Veri setinde eksik değer bulunmamaktadır.")

    print("\n--- Sınıf Dağılımı ---")
    class_counts = df['Sınıf'].value_counts()
    plt.figure(figsize=(10, 6))
    sns.barplot(x=class_counts.index, y=class_counts.values, palette="viridis")
    plt.title('Sınıf Dağılımı')
    plt.xlabel('Sınıf')
    plt.ylabel('Şikayet Sayısı')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

    print("\n--- Şikayet Metni Uzunluk Analizi ---")
    df['Metin Uzunluğu (Kelime)'] = df['Şikayet Metni'].apply(lambda x: len(str(x).split()))
    df['Metin Uzunluğu (Karakter)'] = df['Şikayet Metni'].apply(lambda x: len(str(x)))

    print(df[['Metin Uzunluğu (Kelime)', 'Metin Uzunluğu (Karakter)']].describe())

    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    sns.histplot(df['Metin Uzunluğu (Kelime)'], kde=True, bins=50)
    plt.title('Metin Uzunluğu Dağılımı (Kelime Sayısı)')
    plt.xlabel('Kelime Sayısı')
    plt.ylabel('Frekans')

    plt.subplot(1, 2, 2)
    sns.histplot(df['Metin Uzunluğu (Karakter)'], kde=True, bins=50)
    plt.title('Metin Uzunluğu Dağılımı (Karakter Sayısı)')
    plt.xlabel('Karakter Sayısı')
    plt.ylabel('Frekans')
    plt.tight_layout()
    plt.show()

    print("\n--- Sınıflara Göre Ortalama Metin Uzunlukları ---")
    print(df.groupby('Sınıf')[['Metin Uzunluğu (Kelime)', 'Metin Uzunluğu (Karakter)']].mean())

except FileNotFoundError:
    print(f"Hata: '{file_name}' bulunamadı. Lütfen Google Drive yolunu kontrol edin veya dosyayı Colab ortamına yükleyin.")
    exit()
except Exception as e:
    print(f"Veri yüklenirken veya EDA sırasında bir hata oluştu: {e}")
    exit()

def preprocess_text(text):
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    return text

print("--- Örnek Ön İşleme ---")
sample_text_before = df['Şikayet Metni'].iloc[0]
sample_text_after = preprocess_text(sample_text_before)
print(f"Orijinal Metin: {sample_text_before}")
print(f"Ön İşlenmiş Metin (Basit): {sample_text_after}")

X = df['Şikayet Metni']
y = df['Sınıf']

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

print("\n--- Sınıf Etiketleri ve Kodları ---")
class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))
print(class_mapping)

X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded,
    test_size=0.2,
    random_state=42,
    stratify=y_encoded
)

print(f"\nEğitim seti boyutu: {X_train.shape[0]} ({len(X_train)/len(X)*100:.2f}%)")
print(f"Test seti boyutu: {X_test.shape[0]} ({len(X_test)/len(X)*100:.2f}%)")

print("\nEğitim Seti Sınıf Dağılımı:")
print(pd.Series(y_train).map({v: k for k, v in class_mapping.items()}).value_counts(normalize=True))
print("\nTest Seti Sınıf Dağılımı:")
print(pd.Series(y_test).map({v: k for k, v in class_mapping.items()}).value_counts(normalize=True))

common_tfidf = TfidfVectorizer(
    ngram_range=(1, 2),
    max_df=0.95,
    min_df=2,
)

pipeline_nb = Pipeline([
    ('tfidf', common_tfidf),
    ('clf', MultinomialNB()),
])

pipeline_lr = Pipeline([
    ('tfidf', common_tfidf),
    ('clf', LogisticRegression(
        solver='liblinear',
        random_state=42,
        class_weight='balanced',
        max_iter=1000
    )),
])

pipeline_svc = Pipeline([
    ('tfidf', common_tfidf),
    ('clf', LinearSVC(
        random_state=42,
        class_weight='balanced',
        dual=True,
        max_iter=2000
    )),
])

pipelines = [pipeline_nb, pipeline_lr, pipeline_svc]
pipeline_names = ['Naive Bayes', 'Logistic Regression', 'Linear SVC']

cv_folds = 5
results = []

print(f"\n--- {cv_folds}-Katlı Çapraz Doğrulama Sonuçları ---")

for i, pipeline in enumerate(pipelines):
    model_name = pipeline_names[i]
    print(f"\n===== {model_name} Modeli Değerlendiriliyor =====")

    cv_accuracy = cross_val_score(pipeline, X, y_encoded, cv=cv_folds, scoring='accuracy', n_jobs=-1)
    cv_f1_macro = cross_val_score(pipeline, X, y_encoded, cv=cv_folds, scoring='f1_macro', n_jobs=-1)

    print(f"  Ortalama CV Accuracy: {cv_accuracy.mean():.4f} (+/- {cv_accuracy.std() * 2:.4f})")
    print(f"  Ortalama CV F1 Macro: {cv_f1_macro.mean():.4f} (+/- {cv_f1_macro.std() * 2:.4f})")

    results.append({
        'Model': model_name,
        'CV Accuracy Mean': cv_accuracy.mean(),
        'CV Accuracy Std': cv_accuracy.std(),
        'CV F1 Macro Mean': cv_f1_macro.mean(),
        'CV F1 Macro Std': cv_f1_macro.std(),
    })

results_df = pd.DataFrame(results).sort_values(by='CV F1 Macro Mean', ascending=False)
print("\n\n--- Çapraz Doğrulama Sonuç Özeti (F1 Macro'ya göre sıralı) ---")
print(results_df)

best_initial_model_name = results_df['Model'].iloc[0]
best_initial_pipeline_index = pipeline_names.index(best_initial_model_name)
best_pipeline_for_tuning = pipelines[best_initial_pipeline_index]

print(f"\nHiperparametre optimizasyonu için seçilen en iyi başlangıç modeli: {best_initial_model_name}")

print(f"\n===== {best_initial_model_name} için Hiperparametre Optimizasyonu (GridSearchCV) ===== ")

param_grid = {}

if best_initial_model_name == 'Linear SVC':
    param_grid = [
        {'tfidf__max_df': [0.9, 0.95], 'tfidf__min_df': [1, 2], 'tfidf__ngram_range': [(1,1), (1,2)],
         'clf__penalty': ['l2'], 'clf__loss': ['hinge', 'squared_hinge'], 'clf__C': [0.1, 1, 10], 'clf__dual': [True, False]},
        {'tfidf__max_df': [0.9, 0.95], 'tfidf__min_df': [1, 2], 'tfidf__ngram_range': [(1,1), (1,2)],
         'clf__penalty': ['l1'], 'clf__loss': ['squared_hinge'], 'clf__C': [0.1, 1, 10], 'clf__dual': [False]}
    ]

elif best_initial_model_name == 'Logistic Regression':
    param_grid = {
        'tfidf__max_df': [0.85, 0.90, 0.95],
        'tfidf__min_df': [1, 2, 3, 5],
        'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],
        'clf__C': [0.1, 1, 10, 100],
        'clf__penalty': ['l1', 'l2'],
        'clf__solver': ['liblinear']
    }
elif best_initial_model_name == 'Naive Bayes':
    param_grid = {
        'tfidf__max_df': [0.85, 0.90, 0.95],
        'tfidf__min_df': [1, 2, 3, 5],
        'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],
        'clf__alpha': [0.01, 0.1, 0.5, 1.0]
    }

if not param_grid:
    print(f"{best_initial_model_name} için tanımlı bir parametre ızgarası yok. GridSearch atlanıyor.")
    best_model_final = best_pipeline_for_tuning
    print("En iyi başlangıç modeli tüm eğitim verisi üzerinde yeniden eğitiliyor...")
    best_model_final.fit(X_train, y_train)

else:
    grid_search = GridSearchCV(best_pipeline_for_tuning, param_grid, cv=cv_folds, n_jobs=-1, verbose=2, scoring='f1_macro')
    print("GridSearch başlatılıyor...")
    grid_search.fit(X_train, y_train)

    print("\n--- En İyi Parametreler ---")
    print(grid_search.best_params_)
    print(f"\nÇapraz doğrulama ile elde edilen en iyi F1 Macro skoru: {grid_search.best_score_:.4f}")

    best_model_final = grid_search.best_estimator_

print("\n--- Optimize Edilmiş/Son Modelin Test Seti Performansı ---")
y_pred_final = best_model_final.predict(X_test)

final_accuracy = accuracy_score(y_test, y_pred_final)
print(f"Son Model Doğruluk: {final_accuracy:.4f}")
print("\nSon Model Sınıflandırma Raporu:")
print(classification_report(y_test, y_pred_final, target_names=label_encoder.classes_, digits=4))

cm_final = confusion_matrix(y_test, y_pred_final)
plt.figure(figsize=(12, 9))
sns.heatmap(cm_final, annot=True, fmt='d', cmap='Blues',
            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Tahmin Edilen Sınıf')
plt.ylabel('Gerçek Sınıf')
plt.title(f'{best_initial_model_name} (Optimize Edilmiş) - Karmaşıklık Matrisi')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()



SUB_CATEGORY_THRESHOLD_COLAB = 0.30

def classify_complaint_with_subcat(description, model_pipeline, encoder, proba_threshold_for_subcat=0.3):
    if not model_pipeline or not encoder:
        return "error", "error", "Model/Encoder yüklenemedi", None

    try:
        main_cat_encoded = model_pipeline.predict([description])[0]
        main_category = encoder.inverse_transform([main_cat_encoded])[0]

        sub_category = main_category
        all_class_names = encoder.classes_
        scores_or_probas_full = {}

        classifier = model_pipeline.named_steps['clf']

        if hasattr(classifier, "predict_proba"):
            probabilities = classifier.predict_proba(model_pipeline.named_steps['tfidf'].transform([description]))[0]
            sorted_indices = np.argsort(probabilities)[::-1]
            scores_or_probas_full = {all_class_names[i]: probabilities[i] for i in range(len(all_class_names))}

            if len(sorted_indices) > 1:
                second_best_idx = sorted_indices[1]
                second_best_proba = probabilities[second_best_idx]
                second_best_cat_name = all_class_names[second_best_idx]

                if main_category != second_best_cat_name and second_best_proba >= proba_threshold_for_subcat:
                    sub_category = second_best_cat_name

        elif hasattr(classifier, "decision_function"):
            scores = classifier.decision_function(model_pipeline.named_steps['tfidf'].transform([description]))[0]
            sorted_indices = np.argsort(scores)[::-1]
            scores_or_probas_full = {all_class_names[i]: scores[i] for i in range(len(all_class_names))}

            if len(sorted_indices) > 1:
                second_best_idx = sorted_indices[1]
                second_best_cat_name = all_class_names[second_best_idx]

                if main_category != second_best_cat_name:
                    score_diff_threshold = 0.5
                    if (scores[sorted_indices[0]] - scores[second_best_idx]) < score_diff_threshold:
                        sub_category = second_best_cat_name
                    else:
                        sub_category = main_category
                        print(f"    (Alt kategori için skor farkı ({scores[sorted_indices[0]] - scores[second_best_idx]:.2f}) > eşik ({score_diff_threshold}))")


        else:
            print("Uyarı: Sınıflandırıcıda olasılık veya karar skoru fonksiyonu bulunamadı.")
            return "complaint", main_category, main_category, None


        return "complaint", main_category, sub_category, scores_or_probas_full

    except Exception as e:
        print(f"Manuel test sırasında hata: {e}")
        import traceback
        traceback.print_exc()
        return "error", "error", "error", None


if 'best_model_final' in locals() and 'label_encoder' in locals():
    test_sikayetler_custom = [
        "Koridorlar aşırı kirli. temizlenmesi gerekiyor",
        "asansorlerden ses geliyor ltfen incelensin",
        "asansörlerden titreşim geliyor",
        "üst kat çok gürültü yapıyor gece yarısı",
        "bahçedeki aydınlatma yanmıyor acil bakım lütfen",
        "Yönetim aidatlarla ilgili hiç bilgi vermiyor şeffaf değiller",
        "otoparkta birisi benim yerime park etmiş sürekli oluyor bu",
        "kapı kolu bozuk, tamir edilmeli acilen",
        "güvenlik görevlisi yine yerinde yok, bu kaçıncı?",
        "çok dağınık bırakılmış",
        "her yer pis ve gürültülü",
        "sigara içiliyor",
        "duvarlarda lekeler görünüyor",
        "duvarladra lkelr görünütpe",
        "kiralara sürekli zam geliyor",
        "elini sallayan herkes binaya girebiliyor",
        "merdivenler çok dik ve ışıklandırma yok, düşeceğim diye korkuyorum",
        "kapıcının maaşı ödenmemiş galiba ortalıkta yok"
    ]

    print(f"\n--- Manuel Test Girişleri (SUB_CATEGORY_THRESHOLD = {SUB_CATEGORY_THRESHOLD_COLAB} predict_proba için) ---")
    for sikayet_metni in test_sikayetler_custom:
        type_, cat, sub_cat, all_scores = classify_complaint_with_subcat(
            sikayet_metni,
            best_model_final,
            label_encoder,
            proba_threshold_for_subcat=SUB_CATEGORY_THRESHOLD_COLAB
        )
        print(f"\nŞikayet: '{sikayet_metni}'")
        print(f"  -> Kategori: {cat}")
        if sub_cat != cat:
            print(f"  -> Alt Kategori: {sub_cat}")
        else:
            print(f"  -> Alt Kategori: (Ana kategori ile aynı veya eşik/fark koşulu sağlanmadı)")

        if all_scores:
            print(f"  -> Skorlar/Olasılıklar (En Yüksek 3):")
            sorted_scores = sorted(all_scores.items(), key=lambda item: item[1], reverse=True)
            for class_name, score_val in sorted_scores[:3]:
                 print(f"     {class_name}: {score_val:.4f}")
        else:
            print("  -> Skorlar/Olasılıklar alınamadı.")
else:
    print("Manuel test için model veya label encoder yüklenemedi.")

import joblib
import sklearn

final_model_to_save = best_model_final

model_filename = 'sikayet_model.joblib'
joblib.dump(final_model_to_save, model_filename)
print(f"Model '{model_filename}' olarak kaydedildi.")

encoder_filename = 'label_encoder.joblib'
joblib.dump(label_encoder, encoder_filename)
print(f"Label Encoder '{encoder_filename}' olarak kaydedildi.")

try:
    from google.colab import files
    files.download(model_filename)
    files.download(encoder_filename)
    print("\nModel ve encoder dosyaları indiriliyor...")
except ImportError:
    print("\nGoogle Colab ortamında değilsiniz. Dosyaları manuel olarak bulun ve indirin.")
    print(f"Kaydedilen dosyalar: {model_filename}, {encoder_filename}")